{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQmxJTMZLtzW"
      },
      "source": [
        "# Data crawling with scrapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331KxoyiLzDh",
        "outputId": "111df9f6-c0b5-4803-e4e6-4fd329bbd80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.7.0)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.2)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.0.6)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.1.0)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (5.5.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.1)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.3)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.7/dist-packages (from scrapy) (38.0.1)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.6)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from scrapy) (3.4.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.8.0)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.21)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (4.1.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->scrapy) (3.0.9)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (3.8.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (1.5.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install scrapy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-WS95CGMDxH",
        "outputId": "8456a5d6-82e7-4960-f19d-1f640aac9e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Module 'chilean_data_explore' already exists\n"
          ]
        }
      ],
      "source": [
        "!scrapy startproject chilean_data_explore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n"
      ],
      "metadata": {
        "id": "6DHjjfHmG1TO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pwd\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "L8yHQ4bUGaR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ktEKleAVsslZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9806625-4082-433b-de42-cf8ab14671d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chilean_data_explore/chilean_data_explore\n",
            "__init__.py  middlewares.py  __pycache__  spiders\n",
            "items.py     pipelines.py    settings.py\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/chilean_data_explore/chilean_data_explore/')\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chilean_data_explore.chilean_data_explore.items import ChileanDataExploreItem"
      ],
      "metadata": {
        "id": "rUwNiy6yKidC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile items.py\n",
        "\n",
        "import scrapy\n",
        "\n",
        "class ChileanDataExploreItem(scrapy.Item):\n",
        "    url = scrapy.Field() # str\n",
        "    article_from = scrapy.Field() # str\n",
        "    article_type = scrapy.Field() # str\n",
        "    title = scrapy.Field() # str\n",
        "    publish_date = scrapy.Field() # str\n",
        "    authors = scrapy.Field() # list json\n",
        "    tags = scrapy.Field() # list json\n",
        "    text = scrapy.Field() # list json\n",
        "    text_html = scrapy.Field() # str\n",
        "    images = scrapy.Field() # list json\n",
        "    video = scrapy.Field() # list json\n",
        "    links = scrapy.Field() # list json\n",
        "\n",
        "from scrapy.item import Item, Field\n",
        "class PropertiesItem(Item):\n",
        "     # Primary fields\n",
        "     title = Field()\n",
        "     price = Field()\n",
        "     description = Field()\n",
        "     address = Field()\n",
        "     image_urls = Field()\n",
        "\n",
        "     # Calculated fields\n",
        "     images = Field()\n",
        "     location = Field()\n",
        "     \n",
        "     # Housekeeping fields\n",
        "     url = Field()\n",
        "     project = Field()\n",
        "     spider = Field()\n",
        "     server = Field()\n",
        "     date = Field()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm0AZwn-I4SK",
        "outputId": "3061ecf6-edd5-4fc1-dfa6-1c12a3895a8e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting items.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b497KTrOMQvL",
        "outputId": "3630f3ca-3712-4fe6-f40d-2bee38377845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chilean_data_explore/chilean_data_explore\n",
            "mkdir: cannot create directory ‘logo’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "os.chdir('/content/chilean_data_explore/chilean_data_explore/spiders')\n",
        "!mkdir logo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tNWJKg5MoDH",
        "outputId": "91c4e0f6-fa26-42c1-a376-3e6530da9c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting quotes_spider.py\n"
          ]
        }
      ],
      "source": [
        "#%%writefile -a /chilean_data_explore/chilean_data_explore/spiders/quotes_spider.py\n",
        "%%writefile quotes_spider.py\n",
        "import scrapy\n",
        "from chilean_data_explore.items import ChileanDataExploreItem\n",
        "\n",
        "import time\n",
        "import re\n",
        "\n",
        "class ChinatimesSpider(scrapy.Spider):\n",
        "    name = 'chinatimes'\n",
        "    allowed_domains = ['chinatimes.com']\n",
        "    base_url = 'https://www.chinatimes.com'\n",
        "\n",
        "    url_array = [\n",
        "      'http://observatorio.ministeriodesarrollosocial.gob.cl/encuesta-casen',\n",
        "      'https://www.sii.cl/sobre_el_sii/estadisticas_de_empresas.html',\n",
        "      'https://www.ide.cl/index.php/informacion-territorial/descargar-informacion-territorial',\n",
        "    ]\n",
        "\n",
        "    date_str = str(time.strftime(\"%F\", time.localtime()))\n",
        "\n",
        "    #custom_settings = {\n",
        "    #    'LOG_FILE': 'log/%s-%s.log' % (name, date_str),\n",
        "    #}\n",
        "\n",
        "    def start_requests(self):\n",
        "        list_url = '%s/realtimenews' % (self.base_url)\n",
        "        yield scrapy.Request(url=list_url, callback=self.parse_list)\n",
        "\n",
        "    def parse_list(self, response):\n",
        "        for page_url in response.css('section.article-list>ul>li h3.title>a::attr(href)').getall():\n",
        "            yield scrapy.Request(url=self.base_url + page_url, callback=self.parse_news)\n",
        "\n",
        "    def parse_news(self, response):\n",
        "        item = ChileanDataExploreItem()\n",
        "\n",
        "        item['url'] = response.url\n",
        "        #item['article_from'] = self.name\n",
        "        #item['article_type'] = 'news'\n",
        "\n",
        "        #item['title'] = self._parse_title(response)\n",
        "        #item['publish_date'] = self._parse_publish_date(response)\n",
        "        #item['authors'] = self._parse_authors(response)\n",
        "        #item['tags'] = self._parse_tags(response)\n",
        "        #item['text'] = self._parse_text(response)\n",
        "        #item['text_html'] = self._parse_text_html(response)\n",
        "        #item['images'] = self._parse_images(response)\n",
        "        #item['video'] = self._parse_video(response)\n",
        "        #item['links'] = self._parse_links(response)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def _parse_title(self, response):\n",
        "        return response.css('article.article-box h1.article-title::text').get()\n",
        "\n",
        "    def _parse_publish_date(self, response):\n",
        "        return response.css('article.article-box time::attr(datetime)').get()\n",
        "\n",
        "    def _parse_authors(self, response):\n",
        "        authors = response.css('article.article-box div.author>a::text').getall()\n",
        "        if len(authors) == 0:\n",
        "            authors = [response.css('article.article-box div.author::text').get(default='').strip()]\n",
        "        return authors\n",
        "\n",
        "    def _parse_tags(self, response):\n",
        "        return response.css('article.article-box div.article-hash-tag a::text').getall()\n",
        "\n",
        "    def _parse_text(self, response):\n",
        "        return response.css('article.article-box div.article-body p::text').getall()\n",
        "\n",
        "    def _parse_text_html(self, response):\n",
        "        return response.css('article.article-box div.article-body').get()\n",
        "\n",
        "    def _parse_images(self, response):\n",
        "        images_list = []\n",
        "        images_list.extend(response.css('article.article-box div.main-figure').css('img::attr(src)').getall())\n",
        "        images_list.extend(response.css('article.article-box div.article-body').css('img::attr(src)').getall())\n",
        "        return images_list\n",
        "\n",
        "    def _parse_video(self, response):\n",
        "        return response.css('article.article-box div.article-body iframe::attr(src)').getall()\n",
        "\n",
        "    def _parse_links(self, response):\n",
        "        return response.css('article.article-box div.article-body').css('a::attr(href)').getall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT91tYzFtJRV",
        "outputId": "f99a9449-b5f8-4a75-f82b-95e0ca490526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-26 02:32:57 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: chilean_data_explore)\n",
            "2022-10-26 02:32:57 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-26 02:32:57 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'chilean_data_explore',\n",
            " 'NEWSPIDER_MODULE': 'chilean_data_explore.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_LOADER_WARN_ONLY': True,\n",
            " 'SPIDER_MODULES': ['chilean_data_explore.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-26 02:32:57 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-26 02:32:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-26 02:32:57 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-26 02:32:57 [scrapy.extensions.telnet] INFO: Telnet Password: 2a76225a477a9518\n",
            "2022-10-26 02:32:57 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-26 02:32:57 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-26 02:32:57 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-26 02:32:57 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-26 02:32:57 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-26 02:32:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-26 02:32:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-26 02:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/robots.txt> (referer: None)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews> (referer: None)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001555-260405> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001632-260410> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001603-260410> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001555-260405>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001555-260405'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001632-260410>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001632-260410'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001603-260410>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001603-260410'}\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001618-260405> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001554-260402> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001638-260402> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001375-260408> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001673-260410> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001606-260402> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001587-260404> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001641-260407> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001608-260421> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001633-260423> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001618-260405>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001618-260405'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001554-260402>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001554-260402'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001638-260402>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001638-260402'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001375-260408>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001375-260408'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001673-260410>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001673-260410'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001606-260402>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001606-260402'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001587-260404>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001587-260404'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001641-260407>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001641-260407'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001608-260421>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001608-260421'}\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001633-260423>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001633-260423'}\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221025005813-260408> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001686-260418> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001685-260410> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001372-260408> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001662-260405> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221025005813-260408>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221025005813-260408'}\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001684-260410> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.chinatimes.com/realtimenews/20221026001699-260407> (referer: https://www.chinatimes.com/realtimenews)\n",
            "2022-10-26 02:32:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001686-260418>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001686-260418'}\n",
            "2022-10-26 02:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001685-260410>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001685-260410'}\n",
            "2022-10-26 02:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001372-260408>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001372-260408'}\n",
            "2022-10-26 02:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001662-260405>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001662-260405'}\n",
            "2022-10-26 02:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001684-260410>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001684-260410'}\n",
            "2022-10-26 02:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.chinatimes.com/realtimenews/20221026001699-260407>\n",
            "{'url': 'https://www.chinatimes.com/realtimenews/20221026001699-260407'}\n",
            "2022-10-26 02:32:59 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-10-26 02:32:59 [scrapy.extensions.feedexport] INFO: Stored json feed (20 items) in: quotes.json\n",
            "2022-10-26 02:32:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 6498,\n",
            " 'downloader/request_count': 22,\n",
            " 'downloader/request_method_count/GET': 22,\n",
            " 'downloader/response_bytes': 312786,\n",
            " 'downloader/response_count': 22,\n",
            " 'downloader/response_status_count/200': 22,\n",
            " 'elapsed_time_seconds': 1.274697,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 26, 2, 32, 59, 123978),\n",
            " 'httpcompression/response_bytes': 1419759,\n",
            " 'httpcompression/response_count': 22,\n",
            " 'item_scraped_count': 20,\n",
            " 'log_count/DEBUG': 45,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 94003200,\n",
            " 'memusage/startup': 94003200,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 22,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 21,\n",
            " 'scheduler/dequeued/memory': 21,\n",
            " 'scheduler/enqueued': 21,\n",
            " 'scheduler/enqueued/memory': 21,\n",
            " 'start_time': datetime.datetime(2022, 10, 26, 2, 32, 57, 849281)}\n",
            "2022-10-26 02:32:59 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ],
      "source": [
        "!scrapy runspider quotes_spider.py -o quotes.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/chilean_data_explore/')\n",
        "!pwd | ls -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUarejI_GFGt",
        "outputId": "163ba603-df16-4d37-8616-f3a086454f68"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 4 root root 4096 Oct 26 02:03 chilean_data_explore\n",
            "-rw-r--r-- 1 root root 2106 Oct 26 02:20 items.csv\n",
            "-rw-r--r-- 1 root root  283 Oct 26 02:03 scrapy.cfg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spider for bcentral.cl"
      ],
      "metadata": {
        "id": "w27N3RGwI1F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/chilean_data_explore/chilean_data_explore/spiders/basic.py\n",
        "import scrapy\n",
        "from chilean_data_explore.items import PropertiesItem \n",
        "from scrapy.loader import ItemLoader\n",
        "import datetime\n",
        "import socket\n",
        "\n",
        "class BasicSpider(scrapy.Spider):\n",
        "    name = 'basic'\n",
        "    allowed_domains = ['bcentral.cl']\n",
        "    start_urls = ['https://si3.bcentral.cl/siete']\n",
        "\n",
        "    def parse(self, response):\n",
        "      loader_item = ItemLoader(item=PropertiesItem(), response=response)\n",
        "      loader_item.add_xpath('title','//title/text()')\n",
        "      loader_item.add_xpath('price','//*[@itemprop=\"price\"][1]/text()', re='[.0-9]+')\n",
        "      loader_item.add_xpath('description','//*[contains(@href, \"html\")]')\n",
        "      loader_item.add_value('server', socket.gethostname())\n",
        "      loader_item.add_value('date', datetime.datetime.now())\n",
        "      return loader_item.load_item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXvokRiuHZ93",
        "outputId": "6475f6a1-c6b0-4d05-f100-0b3527217076"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/chilean_data_explore/chilean_data_explore/spiders/basic.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy crawl basic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNcPAxDZJeSE",
        "outputId": "49aeeb2b-5e49-4a71-ef06-52c9b67fef58"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-26 02:33:00 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: chilean_data_explore)\n",
            "2022-10-26 02:33:00 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-26 02:33:00 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'chilean_data_explore',\n",
            " 'NEWSPIDER_MODULE': 'chilean_data_explore.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['chilean_data_explore.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-26 02:33:00 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-26 02:33:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-26 02:33:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-26 02:33:00 [scrapy.extensions.telnet] INFO: Telnet Password: 444ae5ab0a96d18b\n",
            "2022-10-26 02:33:00 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-26 02:33:00 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-26 02:33:00 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-26 02:33:00 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-26 02:33:00 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-26 02:33:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-26 02:33:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-26 02:33:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://si3.bcentral.cl/ErrorPage.html> from <GET https://si3.bcentral.cl/robots.txt>\n",
            "/usr/local/lib/python3.7/dist-packages/scrapy/core/engine.py:279: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated\n",
            "  return self.download(result, spider) if isinstance(result, Request) else result\n",
            "2022-10-26 02:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://si3.bcentral.cl/ErrorPage.html> (referer: None)\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 8 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 20 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 25 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 28 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 39 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 55 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 84 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 90 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 91 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 95 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:01 [protego] DEBUG: Rule at line 96 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:02 [filelock] DEBUG: Attempting to acquire lock 140645855534608 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:02 [filelock] DEBUG: Lock 140645855534608 acquired on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:02 [filelock] DEBUG: Attempting to release lock 140645855534608 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:02 [filelock] DEBUG: Lock 140645855534608 released on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://si3.bcentral.cl/siete> (referer: None)\n",
            "2022-10-26 02:33:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://si3.bcentral.cl/siete>\n",
            "{'date': [datetime.datetime(2022, 10, 26, 2, 33, 2, 648295)],\n",
            " 'description': ['<a target=\"_blank\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/index.html\">Glosario</a>',\n",
            "                 '<a target=\"_blank\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/index_faq.html\">Preguntas '\n",
            "                 'Frecuentes</a>',\n",
            "                 '<a class=\"nav-link\" target=\"_blank\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/Metodolog_BDE.html\">Metodologías</a>',\n",
            "                 '<a class=\"nav-link\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/BDE_movil.html\">BDE '\n",
            "                 'Móvil</a>'],\n",
            " 'server': ['c1770456d150'],\n",
            " 'title': ['Base de Datos Estadísticos ']}\n",
            "2022-10-26 02:33:02 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-10-26 02:33:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 674,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 38967,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/302': 1,\n",
            " 'elapsed_time_seconds': 2.288006,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 26, 2, 33, 2, 657937),\n",
            " 'item_scraped_count': 1,\n",
            " 'log_count/DEBUG': 23,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 94003200,\n",
            " 'memusage/startup': 94003200,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2022, 10, 26, 2, 33, 0, 369931)}\n",
            "2022-10-26 02:33:02 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy crawl basic -o items.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npKp6C2eADMv",
        "outputId": "e2845470-349e-43b5-d2e3-1f072357a3c6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-26 02:33:05 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: chilean_data_explore)\n",
            "2022-10-26 02:33:05 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-26 02:33:05 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'chilean_data_explore',\n",
            " 'NEWSPIDER_MODULE': 'chilean_data_explore.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['chilean_data_explore.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-26 02:33:05 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-26 02:33:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-26 02:33:05 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-26 02:33:05 [scrapy.extensions.telnet] INFO: Telnet Password: e6be071f2b8f46fd\n",
            "2022-10-26 02:33:05 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-26 02:33:05 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-26 02:33:05 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-26 02:33:05 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-26 02:33:05 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-26 02:33:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-26 02:33:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-26 02:33:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://si3.bcentral.cl/ErrorPage.html> from <GET https://si3.bcentral.cl/robots.txt>\n",
            "/usr/local/lib/python3.7/dist-packages/scrapy/core/engine.py:279: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated\n",
            "  return self.download(result, spider) if isinstance(result, Request) else result\n",
            "2022-10-26 02:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://si3.bcentral.cl/ErrorPage.html> (referer: None)\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 8 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 20 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 25 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 28 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 39 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 55 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 84 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 90 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 91 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 95 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:07 [protego] DEBUG: Rule at line 96 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:08 [filelock] DEBUG: Attempting to acquire lock 140086520649168 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:08 [filelock] DEBUG: Lock 140086520649168 acquired on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:08 [filelock] DEBUG: Attempting to release lock 140086520649168 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:08 [filelock] DEBUG: Lock 140086520649168 released on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://si3.bcentral.cl/siete> (referer: None)\n",
            "2022-10-26 02:33:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://si3.bcentral.cl/siete>\n",
            "{'date': [datetime.datetime(2022, 10, 26, 2, 33, 8, 790274)],\n",
            " 'description': ['<a target=\"_blank\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/index.html\">Glosario</a>',\n",
            "                 '<a target=\"_blank\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/index_faq.html\">Preguntas '\n",
            "                 'Frecuentes</a>',\n",
            "                 '<a class=\"nav-link\" target=\"_blank\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/Metodolog_BDE.html\">Metodologías</a>',\n",
            "                 '<a class=\"nav-link\" '\n",
            "                 'href=\"https://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/BDE_movil.html\">BDE '\n",
            "                 'Móvil</a>'],\n",
            " 'server': ['c1770456d150'],\n",
            " 'title': ['Base de Datos Estadísticos ']}\n",
            "2022-10-26 02:33:08 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-10-26 02:33:08 [scrapy.extensions.feedexport] INFO: Stored csv feed (1 items) in: items.csv\n",
            "2022-10-26 02:33:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 674,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 38967,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/302': 1,\n",
            " 'elapsed_time_seconds': 3.085071,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 26, 2, 33, 8, 796035),\n",
            " 'item_scraped_count': 1,\n",
            " 'log_count/DEBUG': 23,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 94003200,\n",
            " 'memusage/startup': 94003200,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2022, 10, 26, 2, 33, 5, 710964)}\n",
            "2022-10-26 02:33:08 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy parse --spider=basic https://si3.bcentral.cl/siete"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQI8QVlgDB0Y",
        "outputId": "2c5d4afe-7bc9-45f0-b808-f7ee13ef723f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-26 02:33:10 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: chilean_data_explore)\n",
            "2022-10-26 02:33:10 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-26 02:33:10 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'chilean_data_explore',\n",
            " 'NEWSPIDER_MODULE': 'chilean_data_explore.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['chilean_data_explore.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-26 02:33:10 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-26 02:33:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-26 02:33:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-26 02:33:10 [scrapy.extensions.telnet] INFO: Telnet Password: c0b8622ebeee2d77\n",
            "2022-10-26 02:33:10 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-26 02:33:11 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-26 02:33:11 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-26 02:33:11 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-26 02:33:11 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-26 02:33:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-26 02:33:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-26 02:33:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://si3.bcentral.cl/ErrorPage.html> from <GET https://si3.bcentral.cl/robots.txt>\n",
            "/usr/local/lib/python3.7/dist-packages/scrapy/core/engine.py:279: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated\n",
            "  return self.download(result, spider) if isinstance(result, Request) else result\n",
            "2022-10-26 02:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://si3.bcentral.cl/ErrorPage.html> (referer: None)\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 8 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 20 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 25 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 28 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 39 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 55 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 84 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 90 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 91 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 95 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:12 [protego] DEBUG: Rule at line 96 without any user agent to enforce it on.\n",
            "2022-10-26 02:33:13 [filelock] DEBUG: Attempting to acquire lock 140319240342736 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:13 [filelock] DEBUG: Lock 140319240342736 acquired on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:13 [filelock] DEBUG: Attempting to release lock 140319240342736 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:13 [filelock] DEBUG: Lock 140319240342736 released on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-10-26 02:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://si3.bcentral.cl/siete> (referer: None)\n",
            "2022-10-26 02:33:13 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-10-26 02:33:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 674,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 38967,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/302': 1,\n",
            " 'elapsed_time_seconds': 2.177564,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 26, 2, 33, 13, 370314),\n",
            " 'log_count/DEBUG': 22,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 94015488,\n",
            " 'memusage/startup': 94015488,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2022, 10, 26, 2, 33, 11, 192750)}\n",
            "2022-10-26 02:33:13 [scrapy.core.engine] INFO: Spider closed (finished)\n",
            "\n",
            ">>> STATUS DEPTH LEVEL 1 <<<\n",
            "# Scraped Items  ------------------------------------------------------------\n",
            "[{\u001b[33m'\u001b[39;49;00m\u001b[33mdate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [datetime.datetime(\u001b[34m2022\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m, \u001b[34m26\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m33\u001b[39;49;00m, \u001b[34m13\u001b[39;49;00m, \u001b[34m365555\u001b[39;49;00m)],\n",
            "  \u001b[33m'\u001b[39;49;00m\u001b[33mdescription\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33m<a target=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m_blank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33mhref=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/index.html\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m>Glosario</a>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33m<a target=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m_blank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33mhref=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/index_faq.html\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m>Preguntas \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33mFrecuentes</a>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33m<a class=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mnav-link\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m target=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m_blank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33mhref=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/Metodolog_BDE.html\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m>Metodologías</a>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33m<a class=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mnav-link\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33mhref=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://si3.bcentral.cl/estadisticas/Principal1/enlaces/aplicaciones/BDE_movil.html\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m>BDE \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
            "                  \u001b[33m'\u001b[39;49;00m\u001b[33mMóvil</a>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
            "  \u001b[33m'\u001b[39;49;00m\u001b[33mserver\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mc1770456d150\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
            "  \u001b[33m'\u001b[39;49;00m\u001b[33mtitle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mBase de Datos Estadísticos \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]}]\n",
            "\n",
            "# Requests  -----------------------------------------------------------------\n",
            "[]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3fr-sbmiard"
      },
      "source": [
        "# Storing crawled data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Xs4DvVhptd",
        "outputId": "2ecc2cc0-c446-4ebc-ac26-c6d98efa7744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.24.90)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.27.90)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.90->boto3) (1.26.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.90->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.90->boto3) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install boto3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qTH9y60mktG"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import os\n",
        "import requests\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVJmdLnhlp2g"
      },
      "outputs": [],
      "source": [
        "dynamo_client  =  boto3.resource(service_name = 'data_crawled_dydb',region_name = 'us-east-1',\n",
        "              aws_access_key_id = 'AKIA3BS5NFXXXXXXX',\n",
        "              aws_secret_access_key = 'qfGTJL28HrqcbhKCM0t//xxx7gTGG4iNrv3/d94Lsp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3_jZTMKl1QE"
      },
      "outputs": [],
      "source": [
        "product_table = dynamo_client.Table('institution')\n",
        "product_table.table_status\n",
        "\n",
        "product_table_link = dynamo_client.Table('link_collection')\n",
        "product_table_link.table_status\n",
        "\n",
        "product_table_file = dynamo_client.Table('file_collection')\n",
        "product_table_file.table_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sPF8vXMlqko"
      },
      "outputs": [],
      "source": [
        "dynamo_client.get_available_subresources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60fizkKMlXAY"
      },
      "outputs": [],
      "source": [
        "def query_police_department_record_by_guid(guid):  \n",
        "    db = dynamodb_resource()\n",
        "    extra_msg = {\"region_name\": REGION, \"aws_service\": \"dynamodb\", \n",
        "        \"police_department_table\":POLICE_DEPARTMENTS_TABLE,\n",
        "        \"guid\":guid}\n",
        "    log.info(f\"Get PD record by GUID\", extra=extra_msg)\n",
        "    pd_table = db.Table(POLICE_DEPARTMENTS_TABLE)\n",
        "    response = pd_table.get_item(\n",
        "        Key={\n",
        "            'guid': guid\n",
        "            }\n",
        "    )\n",
        "    return response['Item']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-gDjN1cpY01"
      },
      "outputs": [],
      "source": [
        "print(query_police_department_record_by_guid(\"jlkdajfldskj1312312\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0_pb1WDLr-3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gB_b1yYNYbE"
      },
      "source": [
        "#References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCw9Gh1nib7k"
      },
      "source": [
        "> DynamoDB and its purposes\n",
        "\n",
        "*   [A one size fits all database doesn't fit anyone\n",
        "](https://www.allthingsdistributed.com/2018/06/purpose-built-databases-in-aws.html)\n",
        "\n",
        "*   [Amazon DynamoDB](https://aws.amazon.com/dynamodb/)\n",
        "\n",
        "*   [Scaling globally with the new AWS](https://www.allthingsdistributed.com/2022/08/aws-launches-middle-east-uae-region.html)\n",
        "\n",
        "\n",
        "> Interfaces for reliable connections\n",
        "\n",
        "*   [DynamoDB and the AWS SDKs](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.html\n",
        ")\n",
        "\n",
        "*   [Boto3 and Amazon DynamoDB](https://www.section.io/engineering-education/python-boto3-and-amazon-dynamodb-programming-tutorial/)\n",
        "\n",
        "*   [DynamoDb in Python using BOTO3](https://www.analyticsvidhya.com/blog/2022/05/working-with-dynamodb-in-python-using-boto3/)\n",
        "\n",
        "> Scrapy \n",
        "\n",
        "* [Google Colab tips: using both %%writefile magic and %%javascript magic in the same cell\n",
        "](https://stephencowchau.medium.com/google-colab-tips-using-both-writefile-magic-and-javascript-magic-in-the-same-cell-7820e508e455)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tQmxJTMZLtzW",
        "m3fr-sbmiard"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMC67VbbvEBvqwWismFP3Jw"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}