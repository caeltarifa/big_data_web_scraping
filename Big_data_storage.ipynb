{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdi0UQI4DVzlHot0LJukJ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caeltarifa/big_data_web_scraping/blob/main/Big_data_storage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing crawled data "
      ],
      "metadata": {
        "id": "m3fr-sbmiard"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Xs4DvVhptd",
        "outputId": "2ecc2cc0-c446-4ebc-ac26-c6d98efa7744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.24.90)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.27.90)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.90->boto3) (1.26.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.90->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.90->boto3) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install boto3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import os\n",
        "import requests\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "-qTH9y60mktG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dynamo_client  =  boto3.resource(service_name = 'data_crawled_dydb',region_name = 'us-east-1',\n",
        "              aws_access_key_id = 'AKIA3BS5NFXXXXXXX',\n",
        "              aws_secret_access_key = 'qfGTJL28HrqcbhKCM0t//xxx7gTGG4iNrv3/d94Lsp')"
      ],
      "metadata": {
        "id": "IVJmdLnhlp2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_table = dynamo_client.Table('institution')\n",
        "product_table.table_status\n",
        "\n",
        "product_table_link = dynamo_client.Table('link_collection')\n",
        "product_table_link.table_status\n",
        "\n",
        "product_table_file = dynamo_client.Table('file_collection')\n",
        "product_table_file.table_status"
      ],
      "metadata": {
        "id": "p3_jZTMKl1QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dynamo_client.get_available_subresources()"
      ],
      "metadata": {
        "id": "-sPF8vXMlqko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_police_department_record_by_guid(guid):  \n",
        "    db = dynamodb_resource()\n",
        "    extra_msg = {\"region_name\": REGION, \"aws_service\": \"dynamodb\", \n",
        "        \"police_department_table\":POLICE_DEPARTMENTS_TABLE,\n",
        "        \"guid\":guid}\n",
        "    log.info(f\"Get PD record by GUID\", extra=extra_msg)\n",
        "    pd_table = db.Table(POLICE_DEPARTMENTS_TABLE)\n",
        "    response = pd_table.get_item(\n",
        "        Key={\n",
        "            'guid': guid\n",
        "            }\n",
        "    )\n",
        "    return response['Item']"
      ],
      "metadata": {
        "id": "60fizkKMlXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_police_department_record_by_guid(\"jlkdajfldskj1312312\"))"
      ],
      "metadata": {
        "id": "u-gDjN1cpY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r0_pb1WDLr-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data crawling with scrapy"
      ],
      "metadata": {
        "id": "tQmxJTMZLtzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scrapy "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331KxoyiLzDh",
        "outputId": "72a1ff6b-54bb-4a9d-8847-98be8b00daa8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.6.3-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 23.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting service-identity>=18.1.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting itemloaders>=1.0.1\n",
            "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)\n",
            "Collecting Twisted>=18.9.0\n",
            "  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 55.3 MB/s \n",
            "\u001b[?25hCollecting zope.interface>=5.0.0\n",
            "  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 47.6 MB/s \n",
            "\u001b[?25hCollecting itemadapter>=0.1.0\n",
            "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
            "Collecting w3lib>=1.17.0\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting pyOpenSSL>=21.0.0\n",
            "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting PyDispatcher>=2.0.5\n",
            "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
            "Collecting queuelib>=1.4.2\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting protego>=0.1.15\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting cryptography>=3.3\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 59.4 MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.1\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.21)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (4.1.1)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (3.8.0)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.9.24)\n",
            "Building wheels for collected packages: PyDispatcher\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=233fa825ab3ec3d29404a4e46aa79b4a13c34195dec6868cf057513cb19bec52\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d\n",
            "Successfully built PyDispatcher\n",
            "Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.1.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.6.3 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.0.1 zope.interface-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy startproject chilean_data_explore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-WS95CGMDxH",
        "outputId": "fa09327c-2eb8-42e7-9459-d64011f773da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Scrapy project 'chilean_data_explore', using template directory '/usr/local/lib/python3.7/dist-packages/scrapy/templates/project', created in:\n",
            "    /content/chilean_data_explore\n",
            "\n",
            "You can start your first spider with:\n",
            "    cd chilean_data_explore\n",
            "    scrapy genspider example example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/chilean_data_explore/chilean_data_explore/spiders')"
      ],
      "metadata": {
        "id": "b497KTrOMQvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b792f347-9f6d-4a9b-dd1c-a0290237077f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chilean_data_explore/chilean_data_explore/spiders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile -a /chilean_data_explore/chilean_data_explore/spiders/quotes_spider.py\n",
        "%%writefile -a quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "  name = 'quotes'\n",
        "\n",
        "  def start_requests (self):\n",
        "    urls = [\n",
        "      'http://quotes.toscrape.com/page/1/',\n",
        "      'http://quotes.toscrape.com/page/2/',\n",
        "    ]\n",
        "    for url in urls:\n",
        "      yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "  def parse(self, response):\n",
        "    pag=response.url.split('/')[-2]\n",
        "    filename = f'quotes-{page}.html'\n",
        "    with open(filename, 'wb') as f:\n",
        "      f.write(response.body)\n",
        "    self.log(f'Saved file {filename}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tNWJKg5MoDH",
        "outputId": "de92b66e-a3b5-4aa7-9d66-fc418a98f583"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to quotes_spider.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python quotes_spider.py"
      ],
      "metadata": {
        "id": "ktEKleAVsslZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy shell 'https://quotes.toscrape.com'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT91tYzFtJRV",
        "outputId": "7d351f25-bc20-436a-8d23-690ca38bb12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-15 03:33:57 [scrapy.utils.log] INFO: Scrapy 2.6.3 started (bot: chilean_data_explore)\n",
            "2022-10-15 03:33:57 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.14 (default, Sep  8 2022, 00:06:44) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-15 03:33:57 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'chilean_data_explore',\n",
            " 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
            " 'LOGSTATS_INTERVAL': 0,\n",
            " 'NEWSPIDER_MODULE': 'chilean_data_explore.spiders',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['chilean_data_explore.spiders']}\n",
            "2022-10-15 03:33:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-10-15 03:33:57 [scrapy.extensions.telnet] INFO: Telnet Password: 84d5da1a1de7940a\n",
            "2022-10-15 03:33:57 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage']\n",
            "2022-10-15 03:33:57 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-15 03:33:57 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-15 03:33:57 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-15 03:33:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-15 03:33:57 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-15 03:33:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n",
            "2022-10-15 03:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com> (referer: None)\n",
            "[s] Available Scrapy objects:\n",
            "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
            "[s]   crawler    <scrapy.crawler.Crawler object at 0x7f062c1d96d0>\n",
            "[s]   item       {}\n",
            "[s]   request    <GET https://quotes.toscrape.com>\n",
            "[s]   response   <200 https://quotes.toscrape.com>\n",
            "[s]   settings   <scrapy.settings.Settings object at 0x7f062c0e2510>\n",
            "[s]   spider     <DefaultSpider 'default' at 0x7f062b912290>\n",
            "[s] Useful shortcuts:\n",
            "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
            "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
            "[s]   shelp()           Shell help (print this help)\n",
            "[s]   view(response)    View response in a browser\n",
            "\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[8D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#References"
      ],
      "metadata": {
        "id": "3gB_b1yYNYbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> DynamoDB and its purposes\n",
        "\n",
        "*   [A one size fits all database doesn't fit anyone\n",
        "](https://www.allthingsdistributed.com/2018/06/purpose-built-databases-in-aws.html)\n",
        "\n",
        "*   [Amazon DynamoDB](https://aws.amazon.com/dynamodb/)\n",
        "\n",
        "*   [Scaling globally with the new AWS](https://www.allthingsdistributed.com/2022/08/aws-launches-middle-east-uae-region.html)\n",
        "\n",
        "\n",
        "> Interfaces for reliable connections\n",
        "\n",
        "*   [DynamoDB and the AWS SDKs](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.html\n",
        ")\n",
        "\n",
        "*   [Boto3 and Amazon DynamoDB](https://www.section.io/engineering-education/python-boto3-and-amazon-dynamodb-programming-tutorial/)\n",
        "\n",
        "*   [DynamoDb in Python using BOTO3](https://www.analyticsvidhya.com/blog/2022/05/working-with-dynamodb-in-python-using-boto3/)\n",
        "\n",
        "> Scrapy \n",
        "\n",
        "* [Google Colab tips: using both %%writefile magic and %%javascript magic in the same cell\n",
        "](https://stephencowchau.medium.com/google-colab-tips-using-both-writefile-magic-and-javascript-magic-in-the-same-cell-7820e508e455)\n"
      ],
      "metadata": {
        "id": "VCw9Gh1nib7k"
      }
    }
  ]
}