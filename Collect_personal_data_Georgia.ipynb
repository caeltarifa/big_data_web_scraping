{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3fr-sbmiard"
      },
      "source": [
        "# Gerogia state and its depredators"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Solve capchas\n",
        "*   Implement Selenium to dynamic handle of components\n",
        "\n"
      ],
      "metadata": {
        "id": "clfBB69h2As3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ICD6o6RP39m"
      },
      "source": [
        "## 1 Gerogia state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92a_5rLvSUvI"
      },
      "source": [
        "### Installing libraries and creating the project's folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLyvXO8nP5LY"
      },
      "outputs": [],
      "source": [
        "!pip install scrapy \n",
        "!scrapy startproject usa_personal_data\n",
        "!scrapy genspider -l"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the spider"
      ],
      "metadata": {
        "id": "UMEBCaQv5lc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/usa_personal_data/usa_personal_data/spiders')\n",
        "!scrapy genspider -t crawl georgia_state https://state.sor.gbi.ga.gov/sort_public/SearchOffender.aspx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs2bIB6J3KsN",
        "outputId": "622d95c2-713f-466b-d8b2-484220db7a89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created spider 'georgia_state' using template 'crawl' in module:\n",
            "  usa_personal_data.spiders.georgia_state\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FciVfL8tSQce"
      },
      "source": [
        "### Selenium / Scrapy class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing Selenium and dependences"
      ],
      "metadata": {
        "id": "KtvHK5Iz56xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o_bi2xNUabG"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "!apt autoremove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jARNHWqCpd2x"
      },
      "source": [
        "#### Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43GA0LGCSWA0",
        "outputId": "af411e47-e3ac-400a-89be-9f7102f10ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/chil_datacrawled_byinst/chil_datacrawled_byinst/spiders/class_selenium_xpath.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/usa_personal_data/usa_personal_data/spiders/class_selenium_xpath.py\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "\n",
        "class selenium_scrapy:\n",
        "  url_list=[]\n",
        "  def driversetup(self):\n",
        "      options = webdriver.ChromeOptions()\n",
        "      #run Selenium in headless mode\n",
        "      options.add_argument('--headless')\n",
        "      options.add_argument('--no-sandbox')\n",
        "      #overcome limited resource problems\n",
        "      options.add_argument('--disable-dev-shm-usage')\n",
        "      options.add_argument(\"lang=en\")\n",
        "      #open Browser in maximized mode\n",
        "      options.add_argument(\"start-maximized\")\n",
        "      #disable infobars\n",
        "      options.add_argument(\"disable-infobars\")\n",
        "      #disable extension\n",
        "      options.add_argument(\"--disable-extensions\")\n",
        "      options.add_argument(\"--incognito\")\n",
        "      options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "      prefs={'download.default_directory':'/content'}\n",
        "      options.add_experimental_option('prefs',prefs)\n",
        "      \n",
        "      driver = webdriver.Chrome(options=options)\n",
        "\n",
        "      driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\")\n",
        "\n",
        "      return driver\n",
        "    \n",
        "  def pagesource(self,url):\n",
        "      driver = self.driversetup()\n",
        "      driver.get(url)\n",
        "      #soup = BeautifulSoup(driver.page_source)\n",
        "      soup=driver.find_elements(By.XPATH, '//a[starts-with(@onclick, \"SetCapitu\")]' )\n",
        "      self.url_list = []\n",
        "      for a in soup:\n",
        "        self.url_list.append(self.url_title(a.get_attribute('onclick')))\n",
        "      driver.close()\n",
        "\n",
        "  def url_title(self,t):\n",
        "      replacements = [\n",
        "        (\"'\",\"\"),\n",
        "        (\")\",\"\"),\n",
        "        (\"(\",\"\"),\n",
        "        (\", \",\"/\"),\n",
        "        (\"SetCapitulo\",\"\"),\n",
        "      ]\n",
        "      for x,y in replacements:\n",
        "        t=t.replace(x,y)\n",
        "      return t+'/'\n",
        "    \n",
        "  def click_element_bcentral(self, url):\n",
        "      driver = self.driversetup()\n",
        "      driver.get(url)\n",
        "\n",
        "      #soup = BeautifulSoup(driver.page_source)\n",
        "      soup=driver.find_elements(By.XPATH, '//*[@id=\"fsTable\"]/div[1]/div[1]/button[5]' )[0]\n",
        "      soup.click()\n",
        "      button_before_click = soup.get_attribute('class')\n",
        "\n",
        "      soup=driver.find_elements(By.XPATH, '//*[@id=\"btnIQYContinue\"]' )[0]\n",
        "      #soup.click()\n",
        "      time.sleep(5)\n",
        "\n",
        "      button_after_click = soup.get_attribute('class')\n",
        "\n",
        "      return \"before_click >>> \" + str(button_before_click) + \"    after click >>\"+ str(button_after_click )\n",
        "      \n",
        "      driver.close()  \n",
        "\n",
        "  def click_exploring_ine(self, url):\n",
        "      driver = self.driversetup()\n",
        "      driver.get(url)\n",
        "\n",
        "      list_response = []\n",
        "      dict_file = {}\n",
        "\n",
        "      ## TITLE PANELS\n",
        "      arr_title = driver.find_elements(By.XPATH, '//*[@id=\"Content_C007_Col00\"]/div/div/div' )\n",
        "      for title in arr_title:\n",
        "        title.click()\n",
        "        time.sleep(3)\n",
        "\n",
        "        ## BUBTITLE PANELS\n",
        "        arr_subtitle = driver.find_elements(By.XPATH, '//*[@id=\"Content_C007_Col01\"]/div/div/div[4]/div/div/div' )\n",
        "        for subtitle in arr_subtitle:\n",
        "          subtitle.click()\n",
        "          time.sleep(3)\n",
        "\n",
        "          arr_link = driver.find_elements(By.XPATH, '//*[@id=\"Content\"]/div[3]/div[3]//a' )\n",
        "          for link in arr_link:\n",
        "\n",
        "            f_name = str(link.text)\n",
        "            *f_name,  format, size, dimension = re.split(r'[;,\\s]\\s*', f_name)\n",
        "            f_name = ' '.join(f_name)\n",
        "            \n",
        "            dict_file = {\n",
        "              'name' : title.text + \" / \" + subtitle.text, \n",
        "              'file_name':f_name,\n",
        "              'file_format':format,\n",
        "              'file_size':size,\n",
        "              'file_dimension':dimension,\n",
        "              \n",
        "              'link': link.get_attribute('href')\n",
        "            }\n",
        "            list_response.append(dict_file)\n",
        "\n",
        "      driver.close()  \n",
        "      return list_response\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sEmiOKLpivo"
      },
      "source": [
        "#### Test of the class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPft6HjiwYp2"
      },
      "outputs": [],
      "source": [
        "#from chil_datacrawled_byinst.chil_datacrawled_byinst.spiders.class_selenium_xpath import selenium_scrapy\n",
        "#\n",
        "#extra_crawled_data = selenium_scrapy()\n",
        "#url='https://www.ine.gob.cl/estadisticas/economia/indices-de-precio-e-inflacion/indice-de-costos-del-transporte'\n",
        "#\n",
        "#list_response = extra_crawled_data.click_exploring_ine(url)\n",
        "#for dic in list_response:\n",
        "#  #print(dic)\n",
        "#  print(dic['name'])\n",
        "#  print(dic['file_name'])\n",
        "#  print(dic['file_format'])\n",
        "#  print(dic['file_size'])\n",
        "#  print(dic['file_dimension'])\n",
        "#  print(dic['link'])\n",
        "#  print(\"___________________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFKF6kwESgdf"
      },
      "source": [
        "### Spider code for GEORGIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxYGkAmtR9AQ",
        "outputId": "700bcfc9-e2c8-4fe6-ac60-a6436a9bdd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/chil_datacrawled_byinst/chil_datacrawled_byinst/spiders/bancocentral_cl.py\n"
          ]
        }
      ],
      "source": [
        "##from chil_datacrawled_byinst.spiders.class_selenium_xpath import selenium_scrapy\n",
        "\n",
        "%%writefile /content/usa_personal_data/usa_personal_data/spiders/georgia_state.py\n",
        "import scrapy\n",
        "\n",
        "from scrapy.spiders import CrawlSpider,Rule\n",
        "from scrapy.linkextractors import LinkExtractor \n",
        "from scrapy import Selector\n",
        "import datetime\n",
        "\n",
        "from chil_datacrawled_byinst.items import ChilDatacrawledByinstItem\n",
        "\n",
        "from chil_datacrawled_byinst.spiders.class_selenium_xpath import selenium_scrapy\n",
        "\n",
        "class BancocentralClSpider(CrawlSpider):\n",
        "    name = 'georgia_state'\n",
        "    allowed_domains = ['state.sor.gbi.ga.gov']\n",
        "    start_urls = ['http://state.sor.gbi.ga.gov/']\n",
        "\n",
        "    link_extractor = LinkExtractor(allow=r'/sort_public/Captcha.aspx')\n",
        "\n",
        "    rules = (\n",
        "        Rule(link_extractor, callback='parse_item', follow=True),\n",
        "    )\n",
        "\n",
        "    def parse_item(self, response):\n",
        "      A = \"//a[contains(@href,'xls') or contains(@href,'pdf') or contains(@href, 'csv') or contains(@href, 'dta') or contains(@href, 'sav')]\" \n",
        "      B = \"//span[contains(@class, 'titulo')]/text() \" \n",
        "      B = \"//a/*[last()]/text() \"\n",
        "      C = '//*[@id=\"Content\"]/div[3]/div'\n",
        "\n",
        "      file = GeorgiaStateItem()\n",
        "      \n",
        "      yield file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0SO2OmAXL2a"
      },
      "source": [
        "### Editing Item Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F542tXycXU2b",
        "outputId": "f1d18ccd-a8d9-489b-a999-cf135a8a291b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/chil_datacrawled_byinst/chil_datacrawled_byinst/items.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/chil_datacrawled_byinst/chil_datacrawled_byinst/items.py\n",
        "import scrapy\n",
        "class GeorgiaStateItem(scrapy.Item):\n",
        "    root_url = scrapy.Field()\n",
        "    date = scrapy.Field()\n",
        "    time = scrapy.Field()\n",
        "    file_title_web = scrapy.Field()\n",
        "    file_stored_name = scrapy.Field()\n",
        "    file_down_url = scrapy.Field()\n",
        "\n",
        "    file_format = scrapy.Field()\n",
        "    file_size = scrapy.Field()\n",
        "    file_dimension = scrapy.Field()\n",
        "    \n",
        "    file_urls = scrapy.Field()\n",
        "    files = scrapy.Field\n",
        "    #pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OFFENDER_CARD = {\n",
        "    'basic_details': {\n",
        "        'Name': None,\n",
        "        'Registration #': None,\n",
        "        'Last Verification Date': None,\n",
        "        'Aliases': None,\n",
        "        'Level': None,\n",
        "        'Status': None,\n",
        "        'Registrant Type': None,\n",
        "        'Registration Start Date': None,\n",
        "        'Registration End Date': None,\n",
        "        'Lifetime Registration': None,\n",
        "    },\n",
        "    'physical_description': {\n",
        "        'Age': None,\n",
        "        'Date of Birth': None,\n",
        "        'Height': None,\n",
        "        'Sex': None,\n",
        "        'Weight': None,\n",
        "        'Race': None,\n",
        "        'Eyes': None,\n",
        "        'Hair': None,\n",
        "        'Scars/Tattoos': None,\n",
        "    },\n",
        "    'addresses': {\n",
        "        'Address': None,\n",
        "        'Work Addresses': None,\n",
        "        'School Addresses': None,\n",
        "        'Volunteer Addresses': None,\n",
        "        'Other Residential Addresses': None,\n",
        "    },\n",
        "    'offenses': [\n",
        "        {\n",
        "            'Description': None,\n",
        "            'Date Convicted': None,\n",
        "            'Conviction State': None,\n",
        "            'Release Date': None,\n",
        "            'Details': None,\n",
        "            'County of Conviction': None,\n",
        "            'Case Number': None,\n",
        "            'Sentence': None,\n",
        "            'State': None,\n",
        "            'Probation Conditions': None,\n",
        "        }\n",
        "    ],\n",
        "    'warrants': [],\n",
        "    'comments': [],\n",
        "    'image_urls': [],\n",
        "    'age': None,\n",
        "    'date_of_birth': None,\n",
        "    'date_of_birth_raw': None,\n",
        "    'state': None,\n",
        "}"
      ],
      "metadata": {
        "id": "AMUbe2Sb7Dtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_B22EPh9Lf"
      },
      "source": [
        "### Setting.py conf for Storing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLM_wpKuiBnY",
        "outputId": "53901a63-fa6b-4528-9eac-828266575f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to /content/chil_datacrawled_byinst/chil_datacrawled_byinst/settings.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile -a /content/chil_datacrawled_byinst/chil_datacrawled_byinst/settings.py\n",
        "\n",
        "#ITEM_PIPELINES = {\n",
        "#  'scrapy.pipelines.files.FilesPipeline': 1,\n",
        "#}\n",
        "\n",
        "FILES_URLS_FIELD = 'file_urls'\n",
        "FILES_RESULT_FIELD = 'files'\n",
        "\n",
        "# 120 days of delay for files expiration\n",
        "FILES_EXPIRES = 120\n",
        "\n",
        "\n",
        "\n",
        "PROXY_LIST = [\n",
        "    \"https://giovwwwl-rotate:dc7luz5au5k5@p.webshare.io:80\",  # 1000 US proxies from webshare\n",
        "]\n",
        "CAPTCHA_API_KEY = \"8319c528f24d11664e92f4aba241d413\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IvETMVqTfYO"
      },
      "source": [
        "### Exec 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQTsWD2FTebn"
      },
      "outputs": [],
      "source": [
        "!scrapy crawl bancocentral_cl -O file_storing_INE.csv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tQmxJTMZLtzW",
        "w27N3RGwI1F0",
        "pA5FqcRkISfk",
        "RDuADs6crNO7",
        "mq9RIExW_JYP",
        "a8mBDBR1azgc",
        "0GY-Ynl3tY_2",
        "ULNiZNh8P08d",
        "92a_5rLvSUvI",
        "FciVfL8tSQce",
        "cFKF6kwESgdf",
        "J0SO2OmAXL2a"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOT/YzxUnQ64B6nlsWMd+5s"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}